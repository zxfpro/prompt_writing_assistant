{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bab9342-7966-47ff-8841-a1cfaec7d8d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py            \u001b[34mgan_ode\u001b[m\u001b[m                vae.ipynb\n",
      "__version__.py         \u001b[34mgan_origin\u001b[m\u001b[m             \u001b[34mvae12\u001b[m\u001b[m\n",
      "\u001b[34marm_origin\u001b[m\u001b[m             \u001b[34mgan_wgan\u001b[m\u001b[m               \u001b[34mvae_bigan\u001b[m\u001b[m\n",
      "base.py                \u001b[34mgan_wgan_gp\u001b[m\u001b[m            \u001b[34mvae_hvae\u001b[m\u001b[m\n",
      "\u001b[34mdiffusion\u001b[m\u001b[m              ganbase.py             \u001b[34mvae_origin\u001b[m\u001b[m\n",
      "\u001b[34mdiffusion_DDPM\u001b[m\u001b[m         \u001b[34mlayertools\u001b[m\u001b[m             \u001b[34mvae_priors\u001b[m\u001b[m\n",
      "\u001b[34mdiffusion_DDPM_picture\u001b[m\u001b[m nn_function.py         \u001b[34mvae_signature_tf\u001b[m\u001b[m\n",
      "\u001b[34mebm\u001b[m\u001b[m                    rbm.py                 \u001b[34mvae_signature_torch\u001b[m\u001b[m\n",
      "\u001b[34mflow\u001b[m\u001b[m                   \u001b[34msbm_origin\u001b[m\u001b[m             \u001b[34mvae_tf\u001b[m\u001b[m\n",
      "\u001b[34mflow2\u001b[m\u001b[m                  \u001b[34msbm_origin111\u001b[m\u001b[m          \u001b[34mvae_timevae\u001b[m\u001b[m\n",
      "\u001b[34mflow_RealNVP\u001b[m\u001b[m           \u001b[34mtransform\u001b[m\u001b[m              \u001b[34mvae_vaegan\u001b[m\u001b[m\n",
      "\u001b[34mflowbasedmodel\u001b[m\u001b[m         utils.py               vaebase.py\n",
      "\u001b[34mgan\u001b[m\u001b[m                    \u001b[34mvae\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ef142b9-5f75-41a0-b5fd-f7b8b88c783e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py     hvae.py         timevae.py\n",
      "distribution.py priors.py       vaes.py\n"
     ]
    }
   ],
   "source": [
    "!ls vae12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8a49932-da23-4833-ad4e-e4b5c56d3bf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %load vae12/vaes.py\n",
    "from .priors import *\n",
    "from gmodel.base import ModelBase,NetworkBase\n",
    "\n",
    "\n",
    "# network\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,encoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "\n",
    "    def reparameterization(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + std * eps\n",
    "\n",
    "    def encode(self, x):\n",
    "        h_e = self.encoder(x)\n",
    "        mu_e, log_var_e = torch.chunk(h_e, 2, dim=1)\n",
    "        return mu_e, log_var_e\n",
    "\n",
    "    def sample(self, x=None, mu_e=None, log_var_e=None):\n",
    "        if (mu_e is None) and (log_var_e is None):\n",
    "            mu_e, log_var_e = self.encode(x)\n",
    "        else:\n",
    "            if (mu_e is None) or (log_var_e is None):\n",
    "                raise ValueError('mu and log-scale can`t be None!')\n",
    "        z = self.reparameterization(mu_e, log_var_e)\n",
    "        return z\n",
    "\n",
    "    def log_prob(self, x=None, mu_e=None, log_var_e=None, z=None):\n",
    "        if x is not None:\n",
    "            mu_e, log_var_e = self.encode(x)\n",
    "            z = self.sample(mu_e=mu_e, log_var_e=log_var_e)\n",
    "        else:\n",
    "            if (mu_e is None) or (log_var_e is None) or (z is None):\n",
    "                raise ValueError('mu, log-scale and z can`t be None!')\n",
    "\n",
    "        return log_normal_diag(z, mu_e, log_var_e)\n",
    "\n",
    "    def forward(self, x, type='log_prob'):\n",
    "        assert type in ['encode', 'log_prob'], 'Type could be either encode or log_prob'\n",
    "        if type == 'log_prob':\n",
    "            return self.log_prob(x)\n",
    "        else:\n",
    "            return self.sample(x)\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, decoder_net, distribution='categorical', num_vals=None):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.decoder = decoder_net\n",
    "        self.distribution = distribution\n",
    "        self.num_vals=num_vals\n",
    "\n",
    "    def decode(self, z):\n",
    "        h_d = self.decoder(z)\n",
    "        if self.distribution == 'categorical':\n",
    "            b = h_d.shape[0]\n",
    "            d = h_d.shape[1]//self.num_vals\n",
    "            h_d = h_d.view(b, d, self.num_vals)\n",
    "            mu_d = torch.softmax(h_d, 2)\n",
    "            return [mu_d]\n",
    "\n",
    "        elif self.distribution == 'bernoulli':\n",
    "            mu_d = torch.sigmoid(h_d)\n",
    "            return [mu_d]\n",
    "\n",
    "        else:\n",
    "            raise ValueError('Either `categorical` or `bernoulli`')\n",
    "    def sample(self, z):\n",
    "        outs = self.decode(z)\n",
    "\n",
    "        if self.distribution == 'categorical':\n",
    "            mu_d = outs[0]\n",
    "            b = mu_d.shape[0]\n",
    "            m = mu_d.shape[1]\n",
    "            mu_d = mu_d.view(mu_d.shape[0], -1, self.num_vals)\n",
    "            p = mu_d.view(-1, self.num_vals)\n",
    "            x_new = torch.multinomial(p, num_samples=1).view(b, m)\n",
    "\n",
    "        elif self.distribution == 'bernoulli':\n",
    "            mu_d = outs[0]\n",
    "            x_new = torch.bernoulli(mu_d)\n",
    "\n",
    "        else:\n",
    "            raise ValueError('Either `categorical` or `bernoulli`')\n",
    "\n",
    "        return x_new\n",
    "\n",
    "    def log_prob(self, x, z):\n",
    "        outs = self.decode(z)\n",
    "        if self.distribution == 'categorical':\n",
    "            mu_d = outs[0]\n",
    "            log_p = log_categorical(x, mu_d, num_classes=self.num_vals, reduction='sum', dim=-1).sum(-1)\n",
    "\n",
    "        elif self.distribution == 'bernoulli':\n",
    "            mu_d = outs[0]\n",
    "            log_p = log_bernoulli(x, mu_d, reduction='sum', dim=-1)\n",
    "\n",
    "        else:\n",
    "            raise ValueError('Either `categorical` or `bernoulli`')\n",
    "        return log_p\n",
    "\n",
    "    def forward(self, z, x=None, type='log_prob'):\n",
    "        assert type in ['decoder', 'log_prob'], 'Type could be either decode or log_prob'\n",
    "        if type == 'log_prob':\n",
    "            return self.log_prob(x, z)\n",
    "        else:\n",
    "            return self.sample(x)\n",
    "\n",
    "\n",
    "class VAENetwork(NetworkBase):\n",
    "    data_demand = None\n",
    "    def __init__(self,input_size,L=16,num_vals=64):\n",
    "        \"\"\"\n",
    "        input_size  : window_size D\n",
    "        L 隐空间的维度   原始为16    更新为2\n",
    "        num——vals  ： digit——dim  分类维数\n",
    "        \"\"\"\n",
    "        super(VAENetwork, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.encoder_net,self.decoder_net = self.set_linear(window_size=input_size[-1],L=L,num_vals=num_vals)\n",
    "        self.num_vals = num_vals\n",
    "        self.L = L\n",
    "\n",
    "    def set_linear(self,window_size,num_vals,L = 2,M = 256):\n",
    "        \"\"\"\n",
    "        D = window_size\n",
    "        \"\"\"\n",
    "\n",
    "        encoder_net = nn.Sequential(nn.Linear(window_size, M), nn.LeakyReLU(),\n",
    "                                    nn.Linear(M, M), nn.LeakyReLU(),\n",
    "                                    nn.Linear(M, 2 * L))\n",
    "\n",
    "        decoder_net = nn.Sequential(nn.Linear(L, M), nn.LeakyReLU(),\n",
    "                                    nn.Linear(M, M), nn.LeakyReLU(),\n",
    "                                    nn.Linear(M, num_vals * window_size))\n",
    "        return encoder_net,decoder_net\n",
    "    \n",
    "    def forward(self,batch):\n",
    "        pass\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"\"\"\n",
    "data_demand     :{self.data_demand}\n",
    "input_size      :{self.input_size}\n",
    "num_vals       :{self.num_vals}\n",
    "L              :{self.L}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class VAEModel(ModelBase):\n",
    "    name = 'VAEpro'\n",
    "    def __init__(self, network:VAENetwork,lr,digit_dim=64,prior_name='vampprior', z_dim=16, likelihood_type='categorical',device='cpu'):\n",
    "        super(VAEModel, self).__init__()\n",
    "        encoder = network.encoder_net\n",
    "        decoder = network.decoder_net\n",
    "        self.encoder = Encoder(encoder)\n",
    "        self.decoder = Decoder(decoder,distribution = likelihood_type,num_vals=digit_dim)\n",
    "\n",
    "        if prior_name in ['standard', 'flow2']:\n",
    "            num_components = 1\n",
    "        elif prior_name[0:3] == 'gtm':\n",
    "            num_components = 4\n",
    "        else:\n",
    "            num_components = 4 ** 2\n",
    "\n",
    "        self.L = network.L\n",
    "        self.D = network.input_size[-1]\n",
    "        self.num_vals = network.num_vals\n",
    "        self.prior_name = prior_name\n",
    "        # Second, we initialize the prior\n",
    "\n",
    "        if prior_name  == 'origin':\n",
    "            self.prior = Prior(L=z_dim)\n",
    "        elif prior_name == 'vampprior':\n",
    "            self.prior = VampPrior(L=self.L, D=self.D, num_vals=self.num_vals, encoder=self.encoder, num_components=num_components)\n",
    "        elif prior_name == 'standard':\n",
    "            self.prior = StandardPrior(L=self.L)\n",
    "        elif prior_name == 'gtm':\n",
    "\n",
    "            gtm_net = nn.Sequential(nn.Linear(2, 256), nn.Tanh(),\n",
    "                                    nn.Linear(256, 256), nn.Tanh(),\n",
    "                                    nn.Linear(256, 2 * self.L))\n",
    "\n",
    "            self.prior = GTMPrior(L=self.L, gtm_net=gtm_net, num_components=num_components, u_min=-10., u_max=10.)\n",
    "        elif prior_name == 'gtm-vampprior':\n",
    "            gtm_net_vamp = nn.Sequential(nn.Linear(2, 256), nn.Tanh(),\n",
    "                                         nn.Linear(256, 256), nn.Tanh(),\n",
    "                                         nn.Linear(256, self.D), nn.Sigmoid())\n",
    "            self.prior = GTMVampPrior(L=self.L, D=self.D, gtm_net=gtm_net_vamp, encoder=encoder, num_points=num_components,\n",
    "                                 u_min=-10., u_max=10., num_vals=self.num_vals)\n",
    "        elif prior_name == 'flow2':\n",
    "            num_flows = 3\n",
    "\n",
    "            # scale (s) network\n",
    "            nets = lambda: nn.Sequential(nn.Linear(self.L // 2, 256), nn.LeakyReLU(),\n",
    "                                         nn.Linear(256, 256), nn.LeakyReLU(),\n",
    "                                         nn.Linear(256, self.L // 2), nn.Tanh())\n",
    "\n",
    "            # translation (t) network\n",
    "            nett = lambda: nn.Sequential(nn.Linear(self.L // 2, 256), nn.LeakyReLU(),\n",
    "                                         nn.Linear(256, 256), nn.LeakyReLU(),\n",
    "                                         nn.Linear(256, self.L // 2))\n",
    "\n",
    "            self.prior = FlowPrior(nets, nett, num_flows=num_flows, D=self.L)\n",
    "        self.digit_dim = digit_dim\n",
    "        self.optimizer = torch.optim.Adamax([p for p in self.parameters() if p.requires_grad == True], lr=lr)\n",
    "        self.lr = lr\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "    def forward(self,batch_data,reduction='avg'):\n",
    "        X,Y = batch_data\n",
    "        X = X.type(torch.FloatTensor)\n",
    "        mu_e, log_var_e = self.encoder.encode(X)\n",
    "        z = self.encoder.sample(mu_e=mu_e, log_var_e=log_var_e)\n",
    "\n",
    "        RE = self.decoder.log_prob(X, z)\n",
    "        KL = (self.prior.log_prob(z) - self.encoder.log_prob(mu_e=mu_e, log_var_e=log_var_e, z=z)).sum(-1)\n",
    "\n",
    "        error = 0\n",
    "        if np.isnan(RE.detach().numpy()).any():\n",
    "            print('RE {}'.format(RE))\n",
    "            error = 1\n",
    "        if np.isnan(KL.detach().numpy()).any():\n",
    "            print('RE {}'.format(KL))\n",
    "            error = 1\n",
    "\n",
    "        if error == 1:\n",
    "            raise ValueError()\n",
    "\n",
    "        if reduction == 'sum':\n",
    "            return -(RE + KL).sum()\n",
    "        else:\n",
    "            return -(RE + KL).mean()\n",
    "\n",
    "\n",
    "    def train(self, batch_data):\n",
    "        loss = self.forward(batch_data)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def generate(self, batch_size, cond=None):\n",
    "        z = self.prior.sample(batch_size=batch_size)\n",
    "        return self.decoder.sample(z)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"\"\"\n",
    "name            :{self.name}\n",
    "prior_name      :{self.prior_name}\n",
    "digit_dim       :{self.digit_dim}\n",
    "lr              :{self.lr}\n",
    "device          :{self.device}\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357c30c1-9845-4785-a0a3-fc4ef55696b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
